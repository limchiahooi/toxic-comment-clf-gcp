<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <link rel="stylesheet" href="style.css">
  <title>Toxic Comment Classification</title>
</head>

<body>

  <h1>Toxic Comment Classification</h1>

  <section class="section">
    
    <form id="submit-form" action="/predict" method="POST" target="result" onsubmit="this.submit(); this.reset(); return false;">
      <label for="quote-field">Type in any text below to check toxicity score:</label><br>
      <textarea onkeyup="textCounter(this,'counter',280);" id="message" type="text" name="comment"  class="search" rows=6 cols=50 maxlength="280" required autofocus></textarea><br>
      <span>Characters remaining: <span id="rem_post" title="280"></span></span>
      <input disabled  maxlength="3" size="3" value="280" id="counter">
      <div class="Bcontainer"><input type="submit" class="button"></div>
    </form>
  </section>

  <section class="section" style=margin-top:20px>      
      <iframe name="result" scrolling="no" frameborder="0" width=400; height=auto; overflow: hidden; ></iframe>
  </section>
    
  <section class="section">
    <strong>About</strong>
      <ul>
        <li><a href="https://www.technologyreview.com/s/603735/its-easy-to-slip-toxic-language-past-alphabets-toxic-comment-detector/">Google</a> defines a toxic comment as "a rude, disrespectful, or unreasonable comment that is likely to make you leave a discussion."</li>
        <li>The objective of this project is to identify and classify toxic comments to help online discussion become more productive and respectful.</li>
        <li>The toxicity scores are generated by a machine learning model trained using a dataset of comments from Wikipedia’s talk page edits downloaded from <a href="https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge">Kaggle</a>.</li>
        <li>The scores are akin to probabilities and range from 0 (non-toxic) to 1 (highly toxic).</li>
        <li>The model is deployed as a REST API using Flask. Flask is a micro web framework written in Python. It can create a REST API that allows you to send data, and receive a prediction as a response.</li>
        <li>For examples of toxic comments in the dataset, click <a href="#" onclick="openList()">here</a> ("viewer discretion is advised").
          <ul style="display:none;" id="list">
            <li>"Fuck you, block me, you faggot pussy!"</li>
            <li>"Stupid peace of shit stop deleting my stuff asshole go die and fall in a hole go to hell!"</li>
            <li>"Well I dont give a fuck what you think you bitch ass motherfucker"</li>
            <li>"Mine dispeared, somebody wax my ass."</li>
            <li>"You are a raging faggot.  Kill yourself."</li>
          </ul>
      </ul>
  </section>

  <div class="footer">
      <p>© 2019 <a href="https://www.linkedin.com/in/limchiahooi">Lim Chia Hooi</a></p>
  </div>

<script src="script.js"></script>
</body>
</html>